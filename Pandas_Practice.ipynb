{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0bdaa0",
   "metadata": {},
   "source": [
    "DataFrame.copy(deep=True)\n",
    "Make a copy of this object’s indices and data.\n",
    "\n",
    "When deep=True (default), a new object will be created with a copy of the calling object’s data and \n",
    "indices. Modifications to the data or indices of the copy will not be \n",
    "reflected in the original object.\n",
    "\n",
    "When deep=False, a new object will be created without copying the calling object’s data or index \n",
    "(only references to the data and index are copied).\n",
    "Any changes to the data of the original will be reflected in the shallow copy (and vice versa).\n",
    "   copy_data = df(same as shallow copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dade591",
   "metadata": {},
   "source": [
    "->read_csv() method of pandas is used to read data from .csv files with default delimiter ',' and .txt files with delimiter as '\\t'\n",
    "\n",
    "->if we want to exclude the index column given by pandas and include one of our columns as index columns we can give input to parameter named 'index_col' the column number where starting column number is 0.\n",
    "\n",
    "->blank values will be read as nan in pandas.but if we want replace missing values as NaN,then we have a parameter named 'na_values' which is a list that takes input of missing values and that values can be replaced with NaN.\n",
    "\n",
    "->na_values: scalar, str, list-like, or dict, optional\n",
    "\n",
    "Additional strings to recognize as NA/NaN. If dict passed, specific per-column NA values. By default the following values are interpreted as NaN: ‘’, ‘#N/A’, ‘#N/A N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’, ‘1.#IND’, ‘1.#QNAN’, ‘<NA>’, ‘N/A’, ‘NA’, ‘NULL’, ‘NaN’, ‘n/a’, ‘nan’, ‘null’.\n",
    "    \n",
    "-> **if we want other than the default values to be considered as NaN we should give that input to na_values parameter**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193900a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           #                   Name  Type 2  HP  Attack  Defense  Sp. Atk  \\\n",
      "Type 1                                                                      \n",
      "Grass      1              Bulbasaur  Poison  45      49       49       65   \n",
      "Grass      2                Ivysaur  Poison  60      62       63       80   \n",
      "Grass      3               Venusaur  Poison  80      82       83      100   \n",
      "Grass      3  VenusaurMega Venusaur  Poison  80     100      123      122   \n",
      "Fire       4             Charmander     NaN  39      52       43       60   \n",
      "...      ...                    ...     ...  ..     ...      ...      ...   \n",
      "Rock     719                Diancie   Fairy  50     100      150      100   \n",
      "Rock     719    DiancieMega Diancie   Fairy  50     160      110      160   \n",
      "Psychic  720    HoopaHoopa Confined   Ghost  80     110       60      150   \n",
      "Psychic  720     HoopaHoopa Unbound    Dark  80     160       60      170   \n",
      "Fire     721              Volcanion   Water  80     110      120      130   \n",
      "\n",
      "         Sp. Def  Speed  Generation  Legendary  \n",
      "Type 1                                          \n",
      "Grass         65     45           1      False  \n",
      "Grass         80     60           1      False  \n",
      "Grass        100     80           1      False  \n",
      "Grass        120     80           1      False  \n",
      "Fire          50     65           1      False  \n",
      "...          ...    ...         ...        ...  \n",
      "Rock         150     50           6       True  \n",
      "Rock         110    110           6       True  \n",
      "Psychic      130     70           6       True  \n",
      "Psychic      130     80           6       True  \n",
      "Fire          90     70           6       True  \n",
      "\n",
      "[800 rows x 11 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('pokemon_data.csv',index_col=2)\n",
    "print(df)\n",
    "df = pd.read_csv('pokemon_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3049088b",
   "metadata": {},
   "source": [
    "## pandas.DataFrame.dropna():\n",
    "-> DataFrame.dropna(*, axis=0, how=_NoDefault.no_default, thresh=_NoDefault.no_default, subset=None, inplace=False\n",
    "-> Removes missing values.\n",
    "\n",
    "Parameters:\n",
    "->'axis': {0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "Determine if rows or columns which contain missing values are removed.\n",
    "\n",
    "0, or ‘index’ : Drop rows which contain missing values.\n",
    "\n",
    "1, or ‘columns’ : Drop columns which contain missing value.\n",
    "\n",
    "->how: {‘any’, ‘all’} default ‘any’\n",
    "Determine if row or column is removed from DataFrame, when we have at least one NA or all NA.\n",
    "\n",
    "‘any’ : If any NA values are present, drop that row or column.\n",
    "\n",
    "‘all’ : If all values are NA, drop that row or column.\n",
    "\n",
    "-> 'thresh':int, optional\n",
    "Require that many non-NA values. Cannot be combined with how.\n",
    "\n",
    "->'subset':column label or sequence of labels, optional\n",
    "Labels along other axis to consider, e.g. if you are dropping rows these would be a list of columns to include.\n",
    "\n",
    "->'inplace': bool, default False\n",
    "Whether to modify the DataFrame rather than creating a new one.\n",
    "\n",
    "->Returns:DataFrame or None\n",
    "\n",
    "DataFrame with NA entries dropped from it or None if inplace=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f29be1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe: \n",
      "        name        toy       born\n",
      "0    Alfred        NaN        NaT\n",
      "1    Batman  Batmobile 1940-04-25\n",
      "2  Catwoman   Bullwhip        NaT\n",
      "\n",
      "using dropna() method with all default parameters: \n",
      "      name        toy       born\n",
      "1  Batman  Batmobile 1940-04-25\n",
      "\n",
      "using dropna() method with how=\"all\"(default is any) : \n",
      "        name        toy       born\n",
      "0    Alfred        NaN        NaT\n",
      "1    Batman  Batmobile 1940-04-25\n",
      "2  Catwoman   Bullwhip        NaT\n",
      "\n",
      "using dropna() method with thresh=2(cannot be combined with how)  : \n",
      "        name        toy       born\n",
      "1    Batman  Batmobile 1940-04-25\n",
      "2  Catwoman   Bullwhip        NaT\n",
      "\n",
      "using dropna() method with axis=\"columns\"(default is axis=\"index\")  : \n",
      "        name\n",
      "0    Alfred\n",
      "1    Batman\n",
      "2  Catwoman\n",
      "\n",
      "using dropna() method with subset = [\"name\",\"toy\"](default is to consider all columns)  : \n",
      "        name        toy       born\n",
      "1    Batman  Batmobile 1940-04-25\n",
      "2  Catwoman   Bullwhip        NaT\n",
      "\n",
      "It printed None because it\"s modified inplace:  None\n",
      "     name        toy       born\n",
      "1  Batman  Batmobile 1940-04-25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_dna = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
    "                   \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
    "                   \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
    "                            pd.NaT]})\n",
    "print('original dataframe: \\n',df_dna)\n",
    "print()\n",
    "print('using dropna() method with all default parameters: \\n',df_dna.dropna())\n",
    "print()\n",
    "print('using dropna() method with how=\"all\"(default is any) : \\n',df_dna.dropna(how = 'all'))\n",
    "#Drop the rows where all elements are missing.\n",
    "print()\n",
    "print('using dropna() method with thresh=2(cannot be combined with how)  : \\n',df_dna.dropna(thresh = 2))\n",
    "#remove only the rows with at least 2 NA values.\n",
    "print()\n",
    "print('using dropna() method with axis=\"columns\"(default is axis=\"index\")  : \\n',\n",
    "df_dna.dropna(axis='columns'))\n",
    "print()\n",
    "print('using dropna() method with subset = [\"name\",\"toy\"](default is to consider all columns)  : \\n',\n",
    "df_dna.dropna(subset = ['name','toy']))\n",
    "#Define in which columns to look for missing values.\n",
    "# as we can see that born column is not considered , the row with na_value in that column is not dropped\n",
    "print()\n",
    "#Keep the DataFrame with valid entries in the same variable.\n",
    "print('It printed None because it\"s modified inplace: ',df_dna.dropna(inplace=True))\n",
    "print(df_dna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b8451",
   "metadata": {},
   "source": [
    "->DataFrame.head(n)\n",
    "The function head returns the first n rows from the dataframe\n",
    "By default, the head() returns first 5 rows\n",
    "\n",
    "->DataFrame.tail(n)\n",
    "The function tail returns the last n rows from the dataframe\n",
    "By default, the tail() returns last 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6bd8897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name  year  selling_price  km_driven    fuel  \\\n",
      "0             Maruti 800 AC  2007          60000      70000  Petrol   \n",
      "1  Maruti Wagon R LXI Minor  2007         135000      50000  Petrol   \n",
      "2      Hyundai Verna 1.6 SX  2012         600000     100000  Diesel   \n",
      "3    Datsun RediGO T Option  2017         250000      46000  Petrol   \n",
      "4     Honda Amaze VX i-DTEC  2014         450000     141000  Diesel   \n",
      "\n",
      "  seller_type transmission         owner  \n",
      "0  Individual       Manual   First Owner  \n",
      "1  Individual       Manual   First Owner  \n",
      "2  Individual       Manual   First Owner  \n",
      "3  Individual       Manual   First Owner  \n",
      "4  Individual       Manual  Second Owner  \n",
      "                                     name  year  selling_price  km_driven  \\\n",
      "4335  Hyundai i20 Magna 1.4 CRDi (Diesel)  2014         409999      80000   \n",
      "4336           Hyundai i20 Magna 1.4 CRDi  2014         409999      80000   \n",
      "4337                  Maruti 800 AC BSIII  2009         110000      83000   \n",
      "4338     Hyundai Creta 1.6 CRDi SX Option  2016         865000      90000   \n",
      "4339                     Renault KWID RXT  2016         225000      40000   \n",
      "\n",
      "        fuel seller_type transmission         owner  \n",
      "4335  Diesel  Individual       Manual  Second Owner  \n",
      "4336  Diesel  Individual       Manual  Second Owner  \n",
      "4337  Petrol  Individual       Manual  Second Owner  \n",
      "4338  Diesel  Individual       Manual   First Owner  \n",
      "4339  Petrol  Individual       Manual   First Owner  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('CAR DETAILS FROM CAR DEKHO.csv')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(df.tail())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b45970c",
   "metadata": {},
   "source": [
    "-> pd.read_excel() function is used to read the data from the excel sheets which have .xlsx extension\n",
    "and if there are group of sheets in one excel file. We can give the excel sheet name we want to parameter 'sheet_name'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cbaaaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4340, step=1)\n",
      "4340\n"
     ]
    }
   ],
   "source": [
    "print(df.index)#The index (row labels) of the DataFrame.\n",
    "print(len(df.index))#indictes no.of rows in the datset\n",
    "# if we set index column other than the pandas given it won't return range() instead it will return\n",
    "#dtypeIndex([values... of index column])\n",
    "# '''Int64Index([ 45,  60,  80,  80,  39,  58,  78,  78,  78,  44,\n",
    "#             ...\n",
    "#              40,  85, 126, 126, 108,  50,  50,  80,  80,  80],\n",
    "#            dtype='int64', name='HP', length=800)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1618e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'year', 'selling_price', 'km_driven', 'fuel', 'seller_type',\n",
      "       'transmission', 'owner'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Getting column names of dataset\n",
    "#columns attribue of dataframe\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbd81cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "year\n",
      "selling_price\n",
      "km_driven\n",
      "fuel\n",
      "seller_type\n",
      "transmission\n",
      "owner\n"
     ]
    }
   ],
   "source": [
    "#method1 for getting column names of dataset\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f1655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'year', 'selling_price', 'km_driven', 'fuel', 'seller_type', 'transmission', 'owner']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'year',\n",
       " 'selling_price',\n",
       " 'km_driven',\n",
       " 'fuel',\n",
       " 'seller_type',\n",
       " 'transmission',\n",
       " 'owner']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method2 for getting column names of dataset(easiest method)\n",
    "print(list(df))\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b3f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name' 'year' 'selling_price' 'km_driven' 'fuel' 'seller_type'\n",
      " 'transmission' 'owner']\n",
      "<class 'numpy.ndarray'>\n",
      "['name', 'year', 'selling_price', 'km_driven', 'fuel', 'seller_type', 'transmission', 'owner']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#method3 for getting column names of dataset\n",
    "print(df.columns.values)\n",
    "print(type(df.columns.values))\n",
    "\n",
    "print(df.columns.values.tolist())\n",
    "print(type(df.columns.values.tolist()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a8bbd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  customerID tenure        Contract PaperlessBilling  \\\n",
      "0             1  8260-NGFNY    One  Month-to-month               No   \n",
      "1             2  2359-QWQUL     39        One year              Yes   \n",
      "2             3  6598/RFFVI      2        One year               No   \n",
      "3             4  IXSTS-8780      6  Month-to-month              Yes   \n",
      "4             5  2674/MIAHT   Four  Month-to-month              Yes   \n",
      "..          ...         ...    ...             ...              ...   \n",
      "252         253  9318-NKNFC    One  Month-to-month              Yes   \n",
      "253         254  9067-SQTNS     44        One year               No   \n",
      "254         255  9067-SQTNS     44        One year               No   \n",
      "255         256  9067-SQTNS     44        One year               No   \n",
      "256         257  9067-SQTNS     44        One year               No   \n",
      "\n",
      "                 PaymentMethod  MonthlyCharges  TotalCharges  gender  \\\n",
      "0                 Mailed check           25.20         25.20  Female   \n",
      "1      Credit card (automatic)          104.70       4134.85  Female   \n",
      "2      Credit card (automatic)           19.30         28.30    Male   \n",
      "3             Electronic check           90.10        521.30  Female   \n",
      "4                 Mailed check           80.30        324.20  Female   \n",
      "..                         ...             ...           ...     ...   \n",
      "252               Mailed check           18.85         18.85    Male   \n",
      "253  Bank transfer (automatic)           20.60        926.00    Male   \n",
      "254  Bank transfer (automatic)           20.60        926.00    Male   \n",
      "255  Bank transfer (automatic)           20.60        926.00    Male   \n",
      "256  Bank transfer (automatic)           20.60        926.00    Male   \n",
      "\n",
      "     SeniorCitizen  ... PhoneService     MultipleLines InternetService  \\\n",
      "0              0.0  ...           No  No phone service             DSL   \n",
      "1              0.0  ...          Yes                No     Fiber optic   \n",
      "2              0.0  ...          Yes                No              No   \n",
      "3              0.0  ...          Yes               Yes     Fiber optic   \n",
      "4              0.0  ...          Yes               Yes     Fiber optic   \n",
      "..             ...  ...          ...               ...             ...   \n",
      "252            0.0  ...          Yes                No              No   \n",
      "253            0.0  ...          Yes                No              No   \n",
      "254            0.0  ...          Yes                No              No   \n",
      "255            0.0  ...          Yes                No              No   \n",
      "256            0.0  ...          Yes                No              No   \n",
      "\n",
      "          OnlineSecurity         OnlineBackup     DeviceProtection  \\\n",
      "0                     No                   No                   No   \n",
      "1                    Yes                   No                  Yes   \n",
      "2    No internet service  No internet service  No internet service   \n",
      "3                     No                  Yes                   No   \n",
      "4                     No                  Yes                   No   \n",
      "..                   ...                  ...                  ...   \n",
      "252  No internet service  No internet service  No internet service   \n",
      "253                  Yes                  Yes  No internet service   \n",
      "254                  Yes                  Yes  No internet service   \n",
      "255                  Yes                  Yes  No internet service   \n",
      "256                  Yes                  Yes  No internet service   \n",
      "\n",
      "             TechSupport          StreamingTV      StreamingMovies Churn  \n",
      "0                     No                   No                   No   Yes  \n",
      "1                    Yes                  Yes                  Yes   Yes  \n",
      "2    No internet service  No internet service  No internet service   Yes  \n",
      "3                     No                  Yes                   No   Yes  \n",
      "4                     No                   No                   No    No  \n",
      "..                   ...                  ...                  ...   ...  \n",
      "252  No internet service  No internet service  No internet service   Yes  \n",
      "253  No internet service                  Yes  No internet service    No  \n",
      "254  No internet service                  Yes  No internet service    No  \n",
      "255  No internet service                  Yes  No internet service    No  \n",
      "256  No internet service                  Yes  No internet service    No  \n",
      "\n",
      "[257 rows x 22 columns]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_missing = pd.read_csv('churn.csv')\n",
    "print(df_missing)\n",
    "print(df_missing['TotalCharges'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae80fa8",
   "metadata": {},
   "source": [
    "## df.info()\n",
    "->Info About the Data The DataFrames object has a method called info()\n",
    "\n",
    "->Print a concise summary of a DataFrame.\n",
    "\n",
    "**This method prints information about a DataFrame including the\n",
    "index dtype and columns and its dtype, non-null values in each column and memory usage**\n",
    "\n",
    "## df.describe():\n",
    "->**It produces an ouput dataframe which contains max,min,std,count,25,50,75 percentiles of columns which have number types**\n",
    "\n",
    "-> Generate descriptive statistics of DataFrame columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7d5d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4340 entries, 0 to 4339\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   name           4340 non-null   object\n",
      " 1   year           4340 non-null   int64 \n",
      " 2   selling_price  4340 non-null   int64 \n",
      " 3   km_driven      4340 non-null   int64 \n",
      " 4   fuel           4340 non-null   object\n",
      " 5   seller_type    4340 non-null   object\n",
      " 6   transmission   4340 non-null   object\n",
      " 7   owner          4340 non-null   object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 271.4+ KB\n",
      "info() function of pandas:\n",
      " None\n",
      "\n",
      " describe() function of pandas \n",
      "               year  selling_price      km_driven\n",
      "count  4340.000000   4.340000e+03    4340.000000\n",
      "mean   2013.090783   5.041273e+05   66215.777419\n",
      "std       4.215344   5.785487e+05   46644.102194\n",
      "min    1992.000000   2.000000e+04       1.000000\n",
      "25%    2011.000000   2.087498e+05   35000.000000\n",
      "50%    2014.000000   3.500000e+05   60000.000000\n",
      "75%    2016.000000   6.000000e+05   90000.000000\n",
      "max    2020.000000   8.900000e+06  806599.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('info() function of pandas:\\n',df.info())\n",
    "\n",
    "\n",
    "print('\\n describe() function of pandas \\n',df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b511aa",
   "metadata": {},
   "source": [
    "## DataFrame.dtypes\n",
    "Return the dtypes in the DataFrame.\n",
    "(by default if any column contains the value NaN it will become object dtype)\n",
    "\n",
    "->This returns a Series with the data type of each column. The result’s index is the original DataFrame’s columns. Columns with mixed types are stored with the object dtype. \n",
    "\n",
    "->Returns:pandas.Series\n",
    "The data type of each column.\n",
    "\n",
    "->DataFrame.dtypes.value_counts() function to get a count of each dtype in the dataframe. Here, we apply the pandas value_counts() function to the pandas series returned by the dtypes attribute.\n",
    "\n",
    "### select_dtypes():\n",
    "->DataFrame.select_dtypes(include=None, exclude=None)\n",
    "\n",
    "->Parameters:include, exclude (scalar or list-like)\n",
    "A selection of dtypes or strings to be included/excluded. At least one of these parameters must be supplied.\n",
    "\n",
    "->Returns:DataFrame\n",
    "The subset of the frame including the dtypes in include and excluding the dtypes in exclude.\n",
    "\n",
    "->Raises: ValueError\n",
    "If both of include and exclude are empty\n",
    "If include and exclude have overlapping elements\n",
    "If any kind of string dtype is passed in.\n",
    "\n",
    "### Unique elements of column:\n",
    "unique() function of numpy library is used to find the unique elements of a column.\n",
    "syntax:numpy.unique(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "668ff829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name               object\n",
      "year                int64\n",
      "selling_price       int64\n",
      "km_driven           int64\n",
      "fuel               object\n",
      "seller_type        object\n",
      "transmission     category\n",
      "owner              object\n",
      "dtype: object\n",
      "\n",
      "object      4\n",
      "int64       3\n",
      "category    1\n",
      "dtype: int64\n",
      "\n",
      "Diesel      2153\n",
      "Petrol      2123\n",
      "CNG           40\n",
      "LPG           23\n",
      "Electric       1\n",
      "Name: fuel, dtype: int64\n",
      "\n",
      "First Owner             2832\n",
      "Second Owner            1106\n",
      "Third Owner              304\n",
      "Fourth & Above Owner      81\n",
      "Test Drive Car            17\n",
      "Name: owner, dtype: int64\n",
      "\n",
      "unique values list in fuel column:  ['CNG' 'Diesel' 'Electric' 'LPG' 'Petrol']\n",
      "unique values list in seller_type:  ['Dealer' 'Individual' 'Trustmark Dealer']\n",
      "unique values list in transmission column:  ['Automatic' 'Manual']\n",
      "\n",
      "unique values in owner column and count of each unique values: ['First Owner' 'Fourth & Above Owner' 'Second Owner' 'Test Drive Car'\n",
      " 'Third Owner'] [2832   81 1106   17  304]\n",
      "\n",
      "dataframe with including object datatype columns only: \n",
      "                                      name    fuel seller_type         owner\n",
      "0                           Maruti 800 AC  Petrol  Individual   First Owner\n",
      "1                Maruti Wagon R LXI Minor  Petrol  Individual   First Owner\n",
      "2                    Hyundai Verna 1.6 SX  Diesel  Individual   First Owner\n",
      "3                  Datsun RediGO T Option  Petrol  Individual   First Owner\n",
      "4                   Honda Amaze VX i-DTEC  Diesel  Individual  Second Owner\n",
      "...                                   ...     ...         ...           ...\n",
      "4335  Hyundai i20 Magna 1.4 CRDi (Diesel)  Diesel  Individual  Second Owner\n",
      "4336           Hyundai i20 Magna 1.4 CRDi  Diesel  Individual  Second Owner\n",
      "4337                  Maruti 800 AC BSIII  Petrol  Individual  Second Owner\n",
      "4338     Hyundai Creta 1.6 CRDi SX Option  Diesel  Individual   First Owner\n",
      "4339                     Renault KWID RXT  Petrol  Individual   First Owner\n",
      "\n",
      "[4340 rows x 4 columns] \n",
      "\n",
      "dataframe with exclude object datatype columns only: \n",
      "       year  selling_price  km_driven transmission\n",
      "0     2007          60000      70000       Manual\n",
      "1     2007         135000      50000       Manual\n",
      "2     2012         600000     100000       Manual\n",
      "3     2017         250000      46000       Manual\n",
      "4     2014         450000     141000       Manual\n",
      "...    ...            ...        ...          ...\n",
      "4335  2014         409999      80000       Manual\n",
      "4336  2014         409999      80000       Manual\n",
      "4337  2009         110000      83000       Manual\n",
      "4338  2016         865000      90000       Manual\n",
      "4339  2016         225000      40000       Manual\n",
      "\n",
      "[4340 rows x 4 columns] \n",
      "\n",
      "dataframe:    a      b    c\n",
      "0  1   True  1.0\n",
      "1  2  False  2.0\n",
      "2  1   True  1.0\n",
      "3  2  False  2.0\n",
      "4  1   True  1.0\n",
      "5  2  False  2.0 \n",
      "\n",
      "including float64 and int64 in the above dataframe: \n",
      "    a    c\n",
      "0  1  1.0\n",
      "1  2  2.0\n",
      "2  1  1.0\n",
      "3  2  2.0\n",
      "4  1  1.0\n",
      "5  2  2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Manual       3892\n",
       "Automatic     448\n",
       "Name: transmission, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#prints each columns and it's data type as Series\n",
    "print(df.dtypes)\n",
    "print()\n",
    "#prints the number of columns having the same datatype as Series\n",
    "print(df.dtypes.value_counts())\n",
    "print()\n",
    "print(df['fuel'].value_counts())\n",
    "print()\n",
    "print(df['owner'].value_counts())\n",
    "print()\n",
    "print('unique values list in fuel column: ',np.unique(df['fuel']))\n",
    "print('unique values list in seller_type: ',np.unique(df['seller_type']))\n",
    "print('unique values list in transmission column: ',np.unique(df['transmission']))\n",
    "#if we give return_counts = True to np.unique() function along with the unique values in that column as \n",
    "#seperate numpy array\n",
    "unique_values,count=np.unique(df['owner'],return_counts = True)\n",
    "print()\n",
    "print('unique values in owner column and count of each unique values:',unique_values,count)\n",
    "#we can either use value_counts or return_counts = True to np.unique() function which will\n",
    "#give the count of each unique value in the column\n",
    "print()\n",
    "dfsd=df.select_dtypes(include='object')\n",
    "print('dataframe with including object datatype columns only: \\n',dfsd,'\\n')\n",
    "dfsd = df.select_dtypes(exclude='object')\n",
    "print('dataframe with exclude object datatype columns only: \\n',dfsd,'\\n')\n",
    "dfsd = pd.DataFrame({'a': [1, 2] * 3,\n",
    "                   'b': [True, False] * 3,\n",
    "                   'c': [1.0, 2.0] * 3})\n",
    "print('dataframe:',dfsd,'\\n')\n",
    "print('including float64 and int64 in the above dataframe: \\n',dfsd.select_dtypes(include=['float64','int64']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9796610",
   "metadata": {},
   "source": [
    "# DataFrame or Series.value_counts():\n",
    "->DataFrame.value_counts(subset=None, normalize=False, sort=True, ascending=False, dropna=True)\n",
    "\n",
    "Parameters:\n",
    "->'subset' :list-like, optional\n",
    "Columns to use when counting unique combinations.\n",
    "\n",
    "-->'normalize':bool, default False\n",
    "Return proportions rather than frequencies.\n",
    "normalize argument is used to count the relative frequency of unique values in a pandas dataframe or series.\n",
    "\n",
    "->'sort':bool, default True\n",
    "Sort by frequencies.\n",
    "\n",
    "->'ascending': bool, default False\n",
    "Sorts in ascending order.\n",
    "\n",
    "->'dropna' :bool, default True\n",
    "Don’t include counts of rows that contain NA values.\n",
    "\n",
    "-> Return a Series containing counts of unique rows in the DataFrame.\n",
    "## extra feature for pandas.Series for value_counts() method:\n",
    "-> 'bins':int, optional\n",
    "Rather than count values, group them into half-open bins, a convenience for pd.cut, only works with numeric data.\n",
    "\n",
    "->bins can be useful for going from a continuous variable to a categorical variable; instead of counting unique apparitions of values, divide the index in the specified number of half-open bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8281ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe: \n",
      "         num_legs  num_wings\n",
      "falcon         2          2\n",
      "dog            4          0\n",
      "cat            4          0\n",
      "ant            6          0 \n",
      "\n",
      "dataframe with value_counts() used with no parameters passed: \n",
      " num_legs  num_wings\n",
      "4         0            2\n",
      "2         2            1\n",
      "6         0            1\n",
      "dtype: int64\n",
      "\n",
      "dataframe with value_counts() with sort = False: \n",
      " num_legs  num_wings\n",
      "2         2            1\n",
      "4         0            2\n",
      "6         0            1\n",
      "dtype: int64\n",
      "\n",
      "dataframe with value_counts() with ascending = True: \n",
      " num_legs  num_wings\n",
      "2         2            1\n",
      "6         0            1\n",
      "4         0            2\n",
      "dtype: int64\n",
      "\n",
      "dataframe with value_counts() with normalize = True: \n",
      " num_legs  num_wings\n",
      "4         0            0.50\n",
      "2         2            0.25\n",
      "6         0            0.25\n",
      "dtype: float64\n",
      "\n",
      "original dataframe to demonstrate dropna parameter: \n",
      "   first_name middle_name\n",
      "0       John       Smith\n",
      "1       Anne        <NA>\n",
      "2       John        <NA>\n",
      "3       Beth      Louise\n",
      "\n",
      "dropna = False: \n",
      " first_name  middle_name\n",
      "Anne        NaN            1\n",
      "Beth        Louise         1\n",
      "John        Smith          1\n",
      "            NaN            1\n",
      "dtype: int64\n",
      "\n",
      "bins parameter only in pandas.Series : \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.9930000000000003, 5.0]    6\n",
       "(5.0, 7.0]                   2\n",
       "(7.0, 9.0]                   2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#creating dataframe for using value_counts() method \n",
    "df_vc_ex = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n",
    "                   'num_wings': [2, 0, 0, 0]},\n",
    "                  index=['falcon', 'dog', 'cat', 'ant'])\n",
    "print('original dataframe: \\n',df_vc_ex,'\\n')\n",
    "print('dataframe with value_counts() used with no parameters passed: \\n',df_vc_ex.value_counts())\n",
    "print()\n",
    "#it defaults to sort in descending order with highest frequency on the top.\n",
    "print('dataframe with value_counts() with sort = False: \\n',df_vc_ex.value_counts(sort=False))\n",
    "print()\n",
    "print('dataframe with value_counts() with ascending = True: \\n',df_vc_ex.value_counts(ascending = True))\n",
    "print()\n",
    "print('dataframe with value_counts() with normalize = True: \\n',df_vc_ex.value_counts(normalize=True))\n",
    "df_vc_na_ex = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],\n",
    "                   'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})\n",
    "print()\n",
    "print('original dataframe to demonstrate dropna parameter: \\n',df_vc_na_ex)\n",
    "print()\n",
    "print('dropna = False: \\n',df_vc_na_ex.value_counts(dropna=False))\n",
    "print()\n",
    "print('bins parameter only in pandas.Series : \\n')\n",
    "my_series = pd.Series([3, 3, 3, 3, 4, 4, 7, 7, 8, 9])\n",
    "\n",
    "#count occurrences of unique values in Series\n",
    "my_series.value_counts(bins=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18036e68",
   "metadata": {},
   "source": [
    "## pandas.Series.nbytes\n",
    "\n",
    "->Return the number of bytes in the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bcb252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bytes of fuel column: with category as datatype:  4380\n",
      "\n",
      "number of bytes of fuel column: with object as datatype:  34720\n",
      "\n",
      "fuel          CNG  Diesel  Electric  LPG  Petrol\n",
      "transmission                                    \n",
      "Automatic       0     254         1    0     193\n",
      "Manual         40    1899         0   23    1930\n"
     ]
    }
   ],
   "source": [
    "print('number of bytes of fuel column: with category as datatype: ',df['fuel'].astype('category').nbytes)\n",
    "print()\n",
    "print('number of bytes of fuel column: with object as datatype: ',df['fuel'].nbytes)\n",
    "print()\n",
    "print(pd.crosstab(index = df['transmission'],columns = df['fuel'] , dropna = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0fe431",
   "metadata": {},
   "source": [
    "# pandas.DataFrame.astype()\n",
    "\n",
    "### This is useful when found out that if anyone of the datatype is read incorrectly and  we can correct it by using astype() method by converting to the data type we want\n",
    "\n",
    "-> DataFrame.astype(dtype, copy=True, errors='raise')\n",
    "Cast a pandas object to a specified dtype dtype.\n",
    "\n",
    "->Parameters\n",
    "'dtype': data type, or dict of column name -> data type\n",
    "\n",
    "Use a numpy.dtype or Python type to cast entire pandas object to the same type. Alternatively, use {col: dtype, …}, where col is a column label and dtype is a numpy.dtype or Python type to cast one or more of the DataFrame’s columns to column-specific types.\n",
    "\n",
    "->'copy':bool, default True\n",
    "Return a copy when copy=True (be very careful setting copy=False as changes to values then may propagate to other pandas objects).\n",
    "\n",
    "->'errors': {‘raise’, ‘ignore’}, default ‘raise’\n",
    "Control raising of exceptions on invalid data for provided dtype.\n",
    "\n",
    "raise : allow exceptions to be raised\n",
    "\n",
    "ignore : suppress exceptions. On error return original object.\n",
    "\n",
    "->Returns: casted same type as caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe3f32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before using astype: \n",
      " col1    int64\n",
      "col2    int64\n",
      "dtype: object\n",
      "\n",
      "converting every column to int32: \n",
      " col1    int32\n",
      "col2    int32\n",
      "dtype: object\n",
      "\n",
      "converting only column1(col1) to int32 using dictionary as input to astype() method: \n",
      " col1    int32\n",
      "col2    int64\n",
      "dtype: object\n",
      "\n",
      "col1    category\n",
      "col2       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df_at = pd.DataFrame(data=d)\n",
    "print('before using astype: \\n',df_at.dtypes)\n",
    "print()\n",
    "print('converting every column to int32: \\n',df_at.astype('int32').dtypes)\n",
    "print()\n",
    "print('converting only column1(col1) to int32 using dictionary as input to astype() method: \\n'\n",
    ",df_at.astype({'col1':'int32'}).dtypes)\n",
    "print()\n",
    "\n",
    "#as it's copy = True we can assign to the same column or row using loc or iloc to reflect the \n",
    "#dtypes change in original dataframe\n",
    "df_at['col1'] = df_at['col1'].astype('category')\n",
    "print(df_at.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e72c19",
   "metadata": {},
   "source": [
    "## DataFrame.pop(item)\n",
    "->Returns the item and drops from frame. Raise KeyError if not found.\n",
    "\n",
    "->Parameters: itemlabel(Label of column to be popped).\n",
    "\n",
    "->Returns: Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3060c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      bird\n",
      "1      bird\n",
      "2    mammal\n",
      "3    mammal\n",
      "Name: class, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>max_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>falcon</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parrot</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lion</td>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monkey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  max_speed\n",
       "0  falcon      389.0\n",
       "1  parrot       24.0\n",
       "2    lion       80.5\n",
       "3  monkey        NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_pop_ex = pd.DataFrame([('falcon', 'bird', 389.0),\n",
    "                   ('parrot', 'bird', 24.0),\n",
    "                   ('lion', 'mammal', 80.5),\n",
    "                   ('monkey', 'mammal', np.nan)],\n",
    "                  columns=('name', 'class', 'max_speed'))\n",
    "print(df_pop_ex.pop('class'))\n",
    "df_pop_ex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18f41f",
   "metadata": {},
   "source": [
    "## pandas.DataFrame.insert()\n",
    "-> DataFrame.insert(loc, column, value, allow_duplicates=_NoDefault.no_default)\n",
    "\n",
    "->Inserts column into DataFrame at specified location.\n",
    "\n",
    "->Raises a ValueError if column is already contained in the DataFrame, unless allow_duplicates is set to True.\n",
    "\n",
    "->Parameters:\n",
    "->'loc':int\n",
    "Insertion index. Must verify 0 <= loc <= len(columns).\n",
    "\n",
    "->'column':str, number, or hashable object\n",
    "Label of the inserted column.\n",
    "\n",
    "->'value':Scalar, Series, or array-like\n",
    "\n",
    "->'allow_duplicates':bool, optional, default lib.no_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "531adfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe: \n",
      "    col1  col2\n",
      "0     1     3\n",
      "1     2     4\n",
      "\n",
      "inserting new column at 1 i.e 2nd column: \n",
      "    col1  newcol  col2\n",
      "0     1      99     3\n",
      "1     2      99     4\n",
      "\n",
      "inserting column with same name with allow_duplicates = True: \n",
      "    col1  col1  newcol  col2\n",
      "0   100     1      99     3\n",
      "1   100     2      99     4\n",
      "\n",
      "using series as the value argument which uses index alignment and places values in same index in df\n",
      "    col0  col1  col1  newcol  col2\n",
      "0   NaN   100     1      99     3\n",
      "1   5.0   100     2      99     4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_ins = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
    "print('original dataframe: \\n',df_ins)\n",
    "print()\n",
    "df_ins.insert(1, \"newcol\", [99, 99])\n",
    "print('inserting new column at 1 i.e 2nd column: \\n',df_ins)\n",
    "print()\n",
    "df_ins.insert(0, \"col1\", [100, 100], allow_duplicates=True)\n",
    "print('inserting column with same name with allow_duplicates = True: \\n',\n",
    "df_ins)\n",
    "#Notice that pandas uses index alignment in case of value from type Series:\n",
    "df_ins.insert(0, \"col0\", pd.Series([5, 6],index = [1,2]))\n",
    "print()\n",
    "print('using series as the value argument which uses index alignment and places values in same index in df\\n'\n",
    ",df_ins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa13951",
   "metadata": {},
   "source": [
    "## pandas.crosstab() function\n",
    "pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\n",
    "->Compute a simple cross tabulation of one,two (or more) factors.\n",
    "\n",
    "->By default, computes a frequency table of the factors unless an array of values and an aggregation function are passed.\n",
    "\n",
    "->Parameters\n",
    "'index':array-like, Series, or list of arrays/Series\n",
    "Values to group by in the rows.\n",
    "\n",
    "'columns':array-like, Series, or list of arrays/Series\n",
    "Values to group by in the columns.\n",
    "\n",
    "->'values':array-like, optional\n",
    "Array of values to aggregate according to the factors. Requires aggfunc be specified.\n",
    "\n",
    "->'rownames':sequence, default None\n",
    "If passed, must match number of row arrays passed.\n",
    "\n",
    "->'colnames':sequence, default None\n",
    "If passed, must match number of column arrays passed.\n",
    "\n",
    "->'aggfunc':function, optional\n",
    "If specified, requires values be specified as well.\n",
    "\n",
    "->'margins':bool, default False\n",
    "Add row/column margins (subtotals).\n",
    "\n",
    "->'margins_name':str, default ‘All’\n",
    "Name of the row/column that will contain the totals when margins is True.\n",
    "\n",
    "->'dropna':bool, default True\n",
    "Do not include columns whose entries are all NaN.\n",
    "\n",
    "->'normalize':bool, {‘all’, ‘index’, ‘columns’}, or {0,1}, default False\n",
    "Normalize by dividing all values by the sum of values.\n",
    "\n",
    "If passed ‘all’ or True, will normalize over all values.\n",
    "\n",
    "If passed ‘index’ will normalize over each row.\n",
    "\n",
    "If passed ‘columns’ will normalize over each column.\n",
    "\n",
    "If margins is True, will also normalize margin values.\n",
    "\n",
    "->Returns: DataFrame\n",
    "Cross tabulation of the data.\n",
    "\n",
    "-> Used for finding frequency distribition and joint,marginal and conditional distributions of two categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a12e041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency of each fuel type excluding NA values:\n",
      " col_0     count\n",
      "fuel           \n",
      "CNG          40\n",
      "Diesel     2153\n",
      "Electric      1\n",
      "LPG          23\n",
      "Petrol     2123\n",
      "\n",
      "frequency of each fuel type excluding NA values using value_counts() method \n",
      " Diesel      2153\n",
      "Petrol      2123\n",
      "CNG           40\n",
      "LPG           23\n",
      "Electric       1\n",
      "Name: fuel, dtype: int64\n",
      "\n",
      "frequency distribution of transmission with respect to fuel type:\n",
      " fuel          CNG  Diesel  Electric  LPG  Petrol\n",
      "transmission                                    \n",
      "Automatic       0     254         1    0     193\n",
      "Manual         40    1899         0   23    1930\n",
      "\n",
      "frequency distribution of transmission with respect to fuel type with margins = True:\n",
      " fuel          CNG  Diesel  Electric  LPG  Petrol  Total\n",
      "transmission                                           \n",
      "Automatic       0     254         1    0     193    448\n",
      "Manual         40    1899         0   23    1930   3892\n",
      "Total          40    2153         1   23    2123   4340\n",
      "\n",
      "Joint probability of fuel type and transmission using normalize = True: \n",
      " fuel               CNG    Diesel  Electric     LPG   Petrol\n",
      "transmission                                               \n",
      "Automatic     0.000000  0.058525   0.00023  0.0000  0.04447\n",
      "Manual        0.009217  0.437558   0.00000  0.0053  0.44470\n",
      "\n",
      "so from the above two-way table we can interpret that probability of a car being automatic transmission and fuel type cng or lpg is 0 and some other interpretations\n",
      "\n",
      "Marginal probability of fuel type and transmission using normalize = True and margins = True: \n",
      " fuel               CNG    Diesel  Electric     LPG    Petrol       All\n",
      "transmission                                                          \n",
      "Automatic     0.000000  0.058525   0.00023  0.0000  0.044470  0.103226\n",
      "Manual        0.009217  0.437558   0.00000  0.0053  0.444700  0.896774\n",
      "All           0.009217  0.496083   0.00023  0.0053  0.489171  1.000000\n",
      "\n",
      "So from the above table we can get marginal probability of each category in both variables against the categories in another categorical variable: like we can say the marginal probability of car being CNG is 0.009217 where it can be automatic or manual transmission\n",
      "In Marginal probability the sum of last row and column probability is 1\n",
      "\n",
      "Conditional probability of fuel type given transmission using normalize = \"index\" and margins = True: \n",
      " fuel               CNG    Diesel  Electric      LPG    Petrol\n",
      "transmission                                                 \n",
      "Automatic     0.000000  0.566964  0.002232  0.00000  0.430804\n",
      "Manual        0.010277  0.487924  0.000000  0.00591  0.495889\n",
      "All           0.009217  0.496083  0.000230  0.00530  0.489171\n",
      "\n",
      "so the above table is about given the transmission conditional probability of fuel type:\n",
      " so given the car is automatic transmission the conditional probability of fuel type cng and lpg is 0\n",
      "In conditional probability each row or column sums to 1 depending upon the parameter we give to\n",
      " normalize.In the last row here given transmission is either manual or automatic.The conditional probability\n",
      " of car fuel type being diesel is 0.496083 and likewise we can see other probabilities as well\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print('frequency of each fuel type excluding NA values:\\n',pd.crosstab(index=df[\"fuel\"]\n",
    ",columns='count',dropna = True))\n",
    "print()\n",
    "#same can be done for seeing frequency distribution of single variables using value_counts() methods\n",
    "#which by default sorts in descending order.\n",
    "print('frequency of each fuel type excluding NA values using value_counts() method \\n'\n",
    ",df['fuel'].value_counts())\n",
    "#main use of pd.crosstab() method is to form two-way tables which we can find distribution of one \n",
    "#categorical variable with respect to another catogerical variable.\n",
    "print()\n",
    "print('frequency distribution of transmission with respect to fuel type:\\n',\n",
    "pd.crosstab(index=df['transmission'],columns=df['fuel']))\n",
    "print()\n",
    "print('frequency distribution of transmission with respect to fuel type with margins = True:\\n',\n",
    "pd.crosstab(index=df['transmission'],columns=df['fuel'],margins = True,margins_name='Total'))\n",
    "print()\n",
    "#so above we have seen frequency distribution of transmission with respect to fuel type in terms of \n",
    "#numbers , so we can also see it in terms of proportion which we can calculate probabilities.\n",
    "\n",
    "#'Joint Probability' : It is the likelihood of two independent events happening at the same time.\n",
    "#to get that , we just have to give normalize = True\n",
    "print('Joint probability of fuel type and transmission using normalize = True: \\n'\n",
    ",pd.crosstab(index=df['transmission'],columns=df['fuel'],normalize= True))\n",
    "print()\n",
    "print('so from the above two-way table we can interpret that probability of a car being automatic',\n",
    "'transmission and fuel type cng or lpg is 0 and some other interpretations')\n",
    "#https://www.statology.org/likelihood-vs-probability/\n",
    "#https://www.khanacademy.org/math/ap-statistics/analyzing-categorical-ap\n",
    "print()\n",
    "print('Marginal probability of fuel type and transmission using normalize = True and margins = True: \\n'\n",
    ",pd.crosstab(index=df['transmission'],columns=df['fuel'],normalize= True,margins = True))\n",
    "print()\n",
    "#Marginal probability is the probability of the occurance of the single event.\n",
    "print('So from the above table we can get marginal probability of each category in both variables against', \n",
    "'the categories in another categorical variable: like we can say the marginal probability of car being',\n",
    "'CNG is 0.009217 where it can be automatic or manual transmission')\n",
    "print('In Marginal probability the sum of last row and column probability is 1')\n",
    "print()\n",
    "#Conditional probability is the probability of event 'A' given the event 'B' has already occured.\n",
    "#normalize = True means it will normaize both columns and rows \n",
    "#to produce conditional probability table, we use normalize = 'index' or 'columns' depending on the result\n",
    "#we want.So, in this case we want to get conditional probability of fueltype given the transmission\n",
    "#is manual or automatic.Therefor we give the event that has occured(index or column) to 'normalize' parameter.\n",
    "print('Conditional probability of fuel type given transmission using normalize = \"index\" and margins = True: \\n'\n",
    ",pd.crosstab(index=df['transmission'],columns=df['fuel'],normalize= 'index',margins = True))\n",
    "print()\n",
    "print('so the above table is about given the transmission conditional probability of fuel type:\\n',\n",
    "'so given the car is automatic transmission the conditional probability of fuel type cng and lpg is 0')\n",
    "print('In conditional probability each row or column sums to 1 depending upon the parameter we give to\\n',\n",
    "'normalize.In the last row here given transmission is either manual or automatic.The conditional probability\\n'\n",
    ",'of car fuel type being diesel is 0.496083 and likewise we can see other probabilities as well')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989d22d",
   "metadata": {},
   "source": [
    "## pandas.DataFrame.corr\n",
    "DataFrame.corr(method='pearson', min_periods=1, numeric_only=_NoDefault.no_default)\n",
    "Compute pairwise correlation of columns, excluding NA/null values.\n",
    "Compute pairwise correlation of columns, excluding NA/null values.\n",
    "\n",
    "->Parameters:\n",
    "->'method':{‘pearson’, ‘kendall’, ‘spearman’} or callable\n",
    "Method of correlation:\n",
    "\n",
    "pearson : standard correlation coefficient\n",
    "\n",
    "kendall : Kendall Tau correlation coefficient\n",
    "\n",
    "spearman : Spearman rank correlation\n",
    "\n",
    "callable: callable with input two 1d ndarrays\n",
    "and returning a float. Note that the returned matrix from corr will have 1 along the diagonals and will be symmetric regardless of the callable’s behavior.\n",
    "\n",
    "->'min_periods':int, optional\n",
    "Minimum number of observations required per pair of columns to have a valid result. Currently only available for Pearson and Spearman correlation.\n",
    "\n",
    "->'numeric_only':bool, default True\n",
    "Include only float, int or boolean data(new in version 1.5.0 and Deprecated since version 1.5.0: The default value of numeric_only will be False in a future version of pandas.)\n",
    "\n",
    "->Returns:DataFrame which represents a Correlation matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9676909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.4\n",
      "                   year  selling_price  km_driven\n",
      "year           1.000000       0.413922  -0.419688\n",
      "selling_price  0.413922       1.000000  -0.192289\n",
      "km_driven     -0.419688      -0.192289   1.000000\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "corr = df.corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a825d8c4",
   "metadata": {},
   "source": [
    "# Indexing and selecting data\n",
    "-> Python's slicing operator [] and attribute/'.' dot operator are used for indexing.\n",
    "\n",
    "-> at and iat functions of pandas.\n",
    "\n",
    "To access a scalar value from the dataframe in the fastest way, we can use .at(),.iat() methods.\n",
    "\n",
    "->.at() provides (row and column)label-based scalar lookups.\n",
    "->.iat() provides integer-based scalar lookups.\n",
    "\n",
    "->at(row_label,column_label) provides the scalar output based on the row_label and column_label provided as input.\n",
    "->iat(row_number,column_number) where row and column numbers start from 0.\n",
    "\n",
    "->group of rows and columns can be accessed through loc and iloc functions of pandas.\n",
    "df.loc(rows,columns)\n",
    "    rows represent the rows to be selected, ':'  represents all rows to be selected.\n",
    "    columns represent the columns to be selected, we can give ['column1','column2' etc...] as input to selct the number of columns through list.\n",
    "    \n",
    "-> .loc[] is primarily label based, but may also be used with a boolean array.\n",
    "\n",
    "Allowed inputs for loc[] are:\n",
    "\n",
    "1.A single label, e.g. 5 or 'a', (note that 5 is interpreted as a label of the index, and never as an integer position along the index).\n",
    "\n",
    "2.A list or array of labels, e.g. ['a', 'b', 'c'].\n",
    "\n",
    "3.A slice object with labels, e.g. 'a':'f'.(Note: unlike python slices , it includes the stop value also)\n",
    "\n",
    "4.A boolean array of the same length as the axis being sliced, e.g. [True, False, True].\n",
    "\n",
    "5.An alignable boolean Series. The index of the key will be aligned before masking.\n",
    "\n",
    "6.An alignable Index. The Index of the returned selection will be the input.\n",
    "\n",
    "7.A callable function with one argument (the calling Series or DataFrame) and that returns valid output for indexing (one of the above)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "603ea2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            max_speed  shield\n",
      "cobra               1       2\n",
      "viper               4       5\n",
      "sidewinder          7       8\n",
      "\n",
      "max_speed    4\n",
      "shield       5\n",
      "Name: viper, dtype: int64\n",
      "\n",
      "       max_speed  shield\n",
      "cobra          1       2\n",
      "viper          4       5\n",
      "\n",
      "cobra\"s max_speed:  1\n",
      "\n",
      "cobra    1\n",
      "viper    4\n",
      "Name: max_speed, dtype: int64\n",
      "\n",
      "            max_speed  shield\n",
      "cobra               1       2\n",
      "sidewinder          7       8\n"
     ]
    }
   ],
   "source": [
    "#df.loc[] exammples:\n",
    "import pandas as pd\n",
    "df_loc_ex = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
    "     index=['cobra', 'viper', 'sidewinder'],\n",
    "     columns=['max_speed', 'shield'])\n",
    "print(df_loc_ex)\n",
    "print()\n",
    "# giving loc[] Single row label as input. Note this returns the row as a Series.\n",
    "print(df_loc_ex.loc['viper'])\n",
    "print()\n",
    "#giving loc[] multiple row label as input in the form of list returns a DataFrame.\n",
    "print(df_loc_ex.loc[['cobra','viper']])\n",
    "print()\n",
    "#giving Single label for row and column as input.\n",
    "print('cobra\"s max_speed: ',df_loc_ex.loc['cobra','max_speed'])\n",
    "print()\n",
    "#Slice with labels for row and single label for column. As mentioned above,\n",
    "#note that both the start and stop of the slice are included.\n",
    "print(df_loc_ex.loc['cobra':'viper', 'max_speed'])\n",
    "print()\n",
    "#Boolean list with the same length as the row axis\n",
    "print(df_loc_ex[[True,False,True]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d5a4507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>2012</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hyundai Xcent 1.2 Kappa S</td>\n",
       "      <td>2016</td>\n",
       "      <td>550000</td>\n",
       "      <td>25000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hyundai Creta 1.6 VTVT S</td>\n",
       "      <td>2015</td>\n",
       "      <td>850000</td>\n",
       "      <td>25000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>2012</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hyundai Xcent 1.2 Kappa S</td>\n",
       "      <td>2016</td>\n",
       "      <td>550000</td>\n",
       "      <td>25000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>Hyundai i10 Sportz 1.2</td>\n",
       "      <td>2011</td>\n",
       "      <td>235000</td>\n",
       "      <td>43100</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>Hyundai Verna 1.6 SX CRDi (O)</td>\n",
       "      <td>2013</td>\n",
       "      <td>500000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>Hyundai i20 Magna 1.4 CRDi (Diesel)</td>\n",
       "      <td>2014</td>\n",
       "      <td>409999</td>\n",
       "      <td>80000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336</th>\n",
       "      <td>Hyundai i20 Magna 1.4 CRDi</td>\n",
       "      <td>2014</td>\n",
       "      <td>409999</td>\n",
       "      <td>80000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338</th>\n",
       "      <td>Hyundai Creta 1.6 CRDi SX Option</td>\n",
       "      <td>2016</td>\n",
       "      <td>865000</td>\n",
       "      <td>90000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name  year  selling_price  km_driven  \\\n",
       "2                    Hyundai Verna 1.6 SX  2012         600000     100000   \n",
       "6               Hyundai Xcent 1.2 Kappa S  2016         550000      25000   \n",
       "8                Hyundai Creta 1.6 VTVT S  2015         850000      25000   \n",
       "15                   Hyundai Verna 1.6 SX  2012         600000     100000   \n",
       "19              Hyundai Xcent 1.2 Kappa S  2016         550000      25000   \n",
       "...                                   ...   ...            ...        ...   \n",
       "4306               Hyundai i10 Sportz 1.2  2011         235000      43100   \n",
       "4322        Hyundai Verna 1.6 SX CRDi (O)  2013         500000     120000   \n",
       "4335  Hyundai i20 Magna 1.4 CRDi (Diesel)  2014         409999      80000   \n",
       "4336           Hyundai i20 Magna 1.4 CRDi  2014         409999      80000   \n",
       "4338     Hyundai Creta 1.6 CRDi SX Option  2016         865000      90000   \n",
       "\n",
       "        fuel seller_type transmission         owner  \n",
       "2     Diesel  Individual       Manual   First Owner  \n",
       "6     Petrol  Individual       Manual   First Owner  \n",
       "8     Petrol  Individual       Manual   First Owner  \n",
       "15    Diesel  Individual       Manual   First Owner  \n",
       "19    Petrol  Individual       Manual   First Owner  \n",
       "...      ...         ...          ...           ...  \n",
       "4306  Petrol      Dealer       Manual   First Owner  \n",
       "4322  Diesel  Individual       Manual   First Owner  \n",
       "4335  Diesel  Individual       Manual  Second Owner  \n",
       "4336  Diesel  Individual       Manual  Second Owner  \n",
       "4338  Diesel  Individual       Manual   First Owner  \n",
       "\n",
       "[821 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtering the data using regex in str.contains() method\n",
    "import re\n",
    "df_Hyundai = df.loc[df['name'].str.contains(pat = r'Hyundai',flags = re.I,regex = True)]\n",
    "\n",
    "df_Hyundai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0745c",
   "metadata": {},
   "source": [
    "## pandas.DataFrame.replace() method\n",
    "-> DataFrame.replace(to_replace=None, value=_NoDefault.no_default, *, inplace=False, limit=None, regex=False, method=_NoDefault.no_default)\n",
    "\n",
    "->Replace values given in to_replace with value.\n",
    "\n",
    "Values of the DataFrame are replaced with other values dynamically.\n",
    "\n",
    "This differs from updating with .loc or .iloc, which require you to specify a location to update with some value.\n",
    "\n",
    "->Parameters\n",
    "'to_replace':str, regex, list, dict, Series, int, float, or None\n",
    "How to find the values that will be replaced.\n",
    "\n",
    "->numeric, str or regex:\n",
    "\n",
    "-numeric: numeric values equal to to_replace will be replaced with value\n",
    "\n",
    "-str: string exactly matching to_replace will be replaced with value\n",
    "\n",
    "-regex: regexs matching to_replace will be replaced with value\n",
    "\n",
    "->list of str, regex, or numeric:\n",
    "\n",
    "-First, if to_replace and value are both lists, they must be the same length.\n",
    "\n",
    "-Second, if regex=True then all of the strings in both lists will be interpreted as regexs otherwise they will match directly. This doesn’t matter much for value since there are only a few possible substitution regexes you can use.\n",
    "\n",
    "str, regex and numeric rules apply as above.\n",
    "\n",
    "->dict:\n",
    "\n",
    "-Dicts can be used to specify different replacement values for different existing values. For example, {'a': 'b', 'y': 'z'} replaces the value ‘a’ with ‘b’ and ‘y’ with ‘z’. To use a dict in this way, the optional value parameter should not be given.\n",
    "\n",
    "-For a DataFrame a dict can specify that different values should be replaced in different columns. For example, {'a': 1, 'b': 'z'} looks for the value 1 in column ‘a’ and the value ‘z’ in column ‘b’ and replaces these values with whatever is specified in value. The value parameter should not be None in this case. You can treat this as a special case of passing two lists except that you are specifying the column to search in.\n",
    "\n",
    "-For a DataFrame nested dictionaries, e.g., {'a': {'b': np.nan}}, are read as follows: look in column ‘a’ for the value ‘b’ and replace it with NaN. The optional value parameter should not be specified to use a nested dict in this way. You can nest regular expressions as well. Note that column names (the top-level dictionary keys in a nested dictionary) cannot be regular expressions.\n",
    "\n",
    "->None:\n",
    "\n",
    "This means that the regex argument must be a string, compiled regular expression, or list, dict, ndarray or Series of such elements. If value is also None then this must be a nested dictionary or Series.\n",
    "\n",
    "See the examples section for examples of each of these.\n",
    "\n",
    "->'value':scalar, dict, list, str, regex, default None\n",
    "Value to replace any values matching to_replace with. For a DataFrame a dict of values can be used to specify which value to use for each column (columns not in the dict will not be filled). Regular expressions, strings and lists or dicts of such objects are also allowed.\n",
    "\n",
    "->'inplace':bool, default False\n",
    "Whether to modify the DataFrame rather than creating a new one.\n",
    "\n",
    "'limit':int, default None\n",
    "Maximum size gap to forward or backward fill.\n",
    "\n",
    "->'regex':bool or same types as to_replace, default False\n",
    "Whether to interpret to_replace and/or value as regular expressions. If this is True then to_replace must be a string. Alternatively, this could be a regular expression or a list, dict, or array of regular expressions in which case to_replace must be None.\n",
    "\n",
    "->'method':{‘pad’, ‘ffill’, ‘bfill’}\n",
    "The method to use when for replacement, when to_replace is a scalar, list or tuple and value is None.\n",
    "\n",
    "Changed in version 0.23.0: Added to DataFrame.\n",
    "\n",
    "->Returns:DataFrame\n",
    "Object after replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efac6816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original series:\n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "\n",
      "replacing 1 with 5 in series: \n",
      " 0    5\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "\n",
      "original dataframe: \n",
      "    A  B  C\n",
      "0  0  5  a\n",
      "1  1  6  b\n",
      "2  2  7  c\n",
      "3  3  8  d\n",
      "4  4  9  e\n",
      "\n",
      "replacing 0 with 5 in dataframe: \n",
      "    A  B  C\n",
      "0  5  5  a\n",
      "1  1  6  b\n",
      "2  2  7  c\n",
      "3  3  8  d\n",
      "4  4  9  e\n",
      "\n",
      "replacing 0,1,2,3 with 4 in the dataframe: \n",
      "    A  B  C\n",
      "0  4  5  a\n",
      "1  4  6  b\n",
      "2  4  7  c\n",
      "3  4  8  d\n",
      "4  4  9  e\n",
      "\n",
      "replacing 0,1,2,3 with 4,3,2,1 respectively in the dataframe: \n",
      "    A  B  C\n",
      "0  4  5  a\n",
      "1  3  6  b\n",
      "2  2  7  c\n",
      "3  1  8  d\n",
      "4  4  9  e\n",
      "\n",
      "replacing 1,3,4 with method bfill which is backward fill in series: \n",
      " 0    2\n",
      "1    2\n",
      "2    5\n",
      "3    5\n",
      "4    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Scalar: `to_replace` and `value`\n",
    "s_re = pd.Series([1, 2, 3, 4, 5])\n",
    "print('original series:\\n',s_re)\n",
    "print()\n",
    "print('replacing 1 with 5 in series: \\n',s_re.replace(to_replace=1,value=5))\n",
    "df_re = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
    "                   'B': [5, 6, 7, 8, 9],\n",
    "                   'C': ['a', 'b', 'c', 'd', 'e']})\n",
    "print()\n",
    "print('original dataframe: \\n',df_re)\n",
    "print()\n",
    "print('replacing 0 with 5 in dataframe: \\n',df_re.replace(to_replace = 0,value = 5))\n",
    "print()\n",
    "\n",
    "#List-like `to_replace`\n",
    "print('replacing 0,1,2,3 with 4 in the dataframe: \\n',df_re.replace(to_replace=[0, 1, 2, 3],value= 4))\n",
    "print()\n",
    "print('replacing 0,1,2,3 with 4,3,2,1 respectively in the dataframe: \\n',\n",
    "df_re.replace(to_replace= [0, 1, 2, 3], value = [4, 3, 2, 1]))\n",
    "print()\n",
    "print('replacing 1,3,4 with method bfill which is backward fill in series: \\n',\n",
    "s_re.replace([1,3,4], method='bfill'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d9b84a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe: \n",
      "    A  B  C\n",
      "0  0  5  a\n",
      "1  1  6  b\n",
      "2  2  7  c\n",
      "3  3  8  d\n",
      "4  4  9  e\n",
      "\n",
      "using dictionary as argument to to_replace which replaces 0 with 10 and 1 with 100: \n",
      "      A  B  C\n",
      "0   10  5  a\n",
      "1  100  6  b\n",
      "2    2  7  c\n",
      "3    3  8  d\n",
      "4    4  9  e\n",
      "\n",
      "using dictionary as arg to replace 0 in A column with 100 and 5 in B column with 100:\n",
      "      A    B  C\n",
      "0  100  100  a\n",
      "1    1    6  b\n",
      "2    2    7  c\n",
      "3    3    8  d\n",
      "4    4    9  e\n",
      "\n",
      "using nested dictinary as arg to replace 0 with 100 and 4 with 400 in column A of dataframe: \n",
      "      A  B  C\n",
      "0  100  5  a\n",
      "1    1  6  b\n",
      "2    2  7  c\n",
      "3    3  8  d\n",
      "4  400  9  e\n"
     ]
    }
   ],
   "source": [
    "#dict-like `to_replace`\n",
    "print('original dataframe: \\n',df_re)\n",
    "print()\n",
    "print('using dictionary as argument to to_replace which replaces 0 with 10 and 1 with 100: \\n',\n",
    "df_re.replace(to_replace={0: 10, 1: 100}))\n",
    "print()\n",
    "print('using dictionary as arg to replace 0 in A column with 100 and 5 in B column with 100:\\n',\n",
    "df_re.replace(to_replace={'A': 0, 'B': 5},value =100))\n",
    "print()\n",
    "print('using nested dictinary as arg to replace 0 with 100 and 4 with 400 in column A of dataframe: \\n',\n",
    "df_re.replace(to_replace={'A': {0: 100, 4: 400}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5b7e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe: \n",
      "       A    B\n",
      "0   bat  abc\n",
      "1   foo  bar\n",
      "2  bait  xyz\n",
      "\n",
      "replacing regex ba(any charcter) with new:\n",
      "       A    B\n",
      "0   new  abc\n",
      "1   foo  new\n",
      "2  bait  xyz\n",
      "\n",
      "replacing ba. with new in column A \n",
      "       A    B\n",
      "0   new  abc\n",
      "1   foo  bar\n",
      "2  bait  xyz\n",
      "\n",
      "giving regex  to_replace: \n",
      "       A    B\n",
      "0   new  abc\n",
      "1   foo  new\n",
      "2  bait  xyz\n",
      "\n",
      "replacing ba. with new and foo with xyz in regex: \n",
      "       A    B\n",
      "0   new  abc\n",
      "1   xyz  new\n",
      "2  bait  xyz\n",
      "\n",
      "replacing ba. and foo with new in regex \n",
      "       A    B\n",
      "0   new  abc\n",
      "1   new  new\n",
      "2  bait  xyz\n",
      "\n",
      "original series: \n",
      " 0    10\n",
      "1     a\n",
      "2     a\n",
      "3     b\n",
      "4     a\n",
      "dtype: object\n",
      "replacing \"a\" without value argument, which does with pad(ffill) method by default\n",
      " 0      10\n",
      "1    None\n",
      "2    None\n",
      "3       b\n",
      "4    None\n",
      "dtype: object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "#Regular expression `to_replace`\n",
    "df_reg = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
    "                   'B': ['abc', 'bar', 'xyz']})\n",
    "print('original dataframe: \\n',df_reg)\n",
    "print()\n",
    "print('replacing regex ba(any charcter) with new:\\n',\n",
    "df_reg.replace(to_replace=r'^ba.$', value='new', regex=True))\n",
    "print()\n",
    "print('replacing ba. with new in column A \\n',\n",
    "df_reg.replace(to_replace ={'A': r'^ba.$'},value ='new', regex=True))\n",
    "print()\n",
    "#we can give the to_replace value to regex with to_replace defaulting to None , So to_replace with regex\n",
    "#and regex=True is same as giving regex = the values that should be given to t0_replace and leaving it.\n",
    "print('giving regex  to_replace: \\n',df_reg.replace(regex=r'^ba.$', value='new'))\n",
    "print()\n",
    "print('replacing ba. with new and foo with xyz in regex: \\n',\n",
    "df_reg.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'}))\n",
    "print()\n",
    "print('replacing ba. and foo with new in regex \\n',df_reg.replace(regex=[r'^ba.$', 'foo'], value='new'))\n",
    "\n",
    "# ''''''When value is not explicitly passed and to_replace is a scalar, list or tuple, replace uses the \n",
    "# method parameter (default ‘pad’) to do the replacement. So this is why the ‘a’ values are \n",
    "# being replaced by 10 in rows 1 and 2 and ‘b’ in row 4 in this case.\n",
    "# When value is not explicitly passed and to_replace is a scalar, list or tuple,\n",
    "# replace uses the method parameter (default ‘pad’)pad ='ffill' to do the replacement.\n",
    "# So this is why the ‘a’ values are being replaced by 10 in rows 1 and 2 and ‘b’ in row 4 in this case.''''''\n",
    "s_de = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
    "print()\n",
    "print('original series: \\n',s_de)\n",
    "print('replacing \"a\" without value argument, which does with pad(ffill) method by default\\n',\n",
    "s_de.replace('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f581f",
   "metadata": {},
   "source": [
    "Groupby in pandas:\n",
    "\n",
    "Groupby mainly refers to a process involving one or more of the following steps they are: \n",
    " \n",
    "Splitting : It is a process in which we split data into group by applying some conditions on datasets.\n",
    "\n",
    "Applying : It is a process in which we apply a function to each group independently\n",
    "\n",
    "Combining : It is a process in which we combine different datasets after applying groupby and results into a data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff176723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     year  selling_price  km_driven    fuel  \\\n",
      "name                                                                          \n",
      "Hyundai Accent CRDi                  2006         170000     245244  Diesel   \n",
      "Hyundai Accent Executive             2013         200000     100000  Petrol   \n",
      "Hyundai Accent Executive CNG         2012         185000     110000     CNG   \n",
      "Hyundai Accent GLE                   2009         114999     106000  Petrol   \n",
      "Hyundai Accent GLE 1                 1999          60000      90000  Petrol   \n",
      "...                                   ...            ...        ...     ...   \n",
      "Hyundai i20 Magna Optional 1.4 CRDi  2013         420000     100000  Diesel   \n",
      "Hyundai i20 Sportz 1.2               2017         700000      90000  Petrol   \n",
      "Hyundai i20 Sportz 1.4 CRDi          2018         750000     110000  Diesel   \n",
      "Hyundai i20 Sportz Option 1.2        2016         475000      25000  Petrol   \n",
      "Hyundai i20 Sportz Petrol            2010         250000      40000  Petrol   \n",
      "\n",
      "                                    seller_type transmission  \\\n",
      "name                                                           \n",
      "Hyundai Accent CRDi                  Individual       Manual   \n",
      "Hyundai Accent Executive             Individual       Manual   \n",
      "Hyundai Accent Executive CNG         Individual       Manual   \n",
      "Hyundai Accent GLE                   Individual       Manual   \n",
      "Hyundai Accent GLE 1                 Individual       Manual   \n",
      "...                                         ...          ...   \n",
      "Hyundai i20 Magna Optional 1.4 CRDi  Individual       Manual   \n",
      "Hyundai i20 Sportz 1.2               Individual       Manual   \n",
      "Hyundai i20 Sportz 1.4 CRDi          Individual       Manual   \n",
      "Hyundai i20 Sportz Option 1.2        Individual       Manual   \n",
      "Hyundai i20 Sportz Petrol            Individual       Manual   \n",
      "\n",
      "                                                    owner  \n",
      "name                                                       \n",
      "Hyundai Accent CRDi                           Third Owner  \n",
      "Hyundai Accent Executive                      Third Owner  \n",
      "Hyundai Accent Executive CNG                 Second Owner  \n",
      "Hyundai Accent GLE                            Third Owner  \n",
      "Hyundai Accent GLE 1                 Fourth & Above Owner  \n",
      "...                                                   ...  \n",
      "Hyundai i20 Magna Optional 1.4 CRDi           First Owner  \n",
      "Hyundai i20 Sportz 1.2                       Second Owner  \n",
      "Hyundai i20 Sportz 1.4 CRDi                  Second Owner  \n",
      "Hyundai i20 Sportz Option 1.2                 First Owner  \n",
      "Hyundai i20 Sportz Petrol                     First Owner  \n",
      "\n",
      "[244 rows x 7 columns]\n",
      "      name  selling_price  km_driven  fuel  seller_type  transmission  owner\n",
      "year                                                                        \n",
      "1992     1              1          1     1            1             1      1\n",
      "1995     1              1          1     1            1             1      1\n",
      "1996     2              2          2     2            2             2      2\n",
      "1997     3              3          3     3            3             3      3\n",
      "1998    12             12         12    12           12            12     12\n",
      "1999    10             10         10    10           10            10     10\n",
      "2000    12             12         12    12           12            12     12\n",
      "2001    20             20         20    20           20            20     20\n",
      "2002    21             21         21    21           21            21     21\n",
      "2003    23             23         23    23           23            23     23\n",
      "2004    42             42         42    42           42            42     42\n",
      "2005    85             85         85    85           85            85     85\n",
      "2006   110            110        110   110          110           110    110\n",
      "2007   134            134        134   134          134           134    134\n",
      "2008   145            145        145   145          145           145    145\n",
      "2009   193            193        193   193          193           193    193\n",
      "2010   234            234        234   234          234           234    234\n",
      "2011   271            271        271   271          271           271    271\n",
      "2012   415            415        415   415          415           415    415\n",
      "2013   386            386        386   386          386           386    386\n",
      "2014   367            367        367   367          367           367    367\n",
      "2015   421            421        421   421          421           421    421\n",
      "2016   357            357        357   357          357           357    357\n",
      "2017   466            466        466   466          466           466    466\n",
      "2018   366            366        366   366          366           366    366\n",
      "2019   195            195        195   195          195           195    195\n",
      "2020    48             48         48    48           48            48     48\n",
      "          name  year  selling_price  km_driven  seller_type  transmission  \\\n",
      "fuel                                                                        \n",
      "CNG         40    40             40         40           40            40   \n",
      "Diesel    2153  2153           2153       2153         2153          2153   \n",
      "Electric     1     1              1          1            1             1   \n",
      "LPG         23    23             23         23           23            23   \n",
      "Petrol    2123  2123           2123       2123         2123          2123   \n",
      "\n",
      "          owner  \n",
      "fuel             \n",
      "CNG          40  \n",
      "Diesel     2153  \n",
      "Electric      1  \n",
      "LPG          23  \n",
      "Petrol     2123  \n",
      "              name\n",
      "transmission      \n",
      "Automatic      448\n",
      "Manual        3892\n"
     ]
    }
   ],
   "source": [
    "#using groupby in df to obtain the sum,mean,count,min,max\n",
    "print(df_Hyundai.groupby(['name']).max())\n",
    "print(df.groupby(['year']).count())\n",
    "print(df.groupby('fuel').count())\n",
    "print(df.groupby('transmission').count()[['name']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3e78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
