{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d4d578",
   "metadata": {},
   "source": [
    "### Cross Validation Techniques \n",
    "Comparing the RandomForest, Svm, Logistic Regression algorithms for classifying the flowers in the\n",
    "load_iris() dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b7f42",
   "metadata": {},
   "source": [
    "### KFold vs StratifiedKFold \n",
    "\n",
    "KFold is a cross-validator that divides the dataset into k folds.\n",
    "\n",
    "Stratified is to ensure that each fold of dataset has the same proportion of observations with a given label.\n",
    "\n",
    "So, it means that StratifiedKFold is the improved version of KFold\n",
    "\n",
    "Therefore,  we should prefer StratifiedKFold over KFold especially when dealing with classification tasks with imbalanced class distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca0f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34935f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset = load_iris()\n",
    "dir(iris_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eedc85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "iris dataset target names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(f'iris dataset feature names: {iris_dataset.feature_names}')\n",
    "print()\n",
    "print(f'iris dataset target names: {iris_dataset.target_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a89ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset data values : [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      "iris datset target values : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print('iris dataset data values :', iris_dataset.data)\n",
    "print()\n",
    "print('iris datset target values :', iris_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0659bd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris = pd.DataFrame(iris_dataset.data , columns = iris_dataset.feature_names)\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1dd82c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = iris_dataset.target\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f905b",
   "metadata": {},
   "source": [
    "#### As we have seen that when using train_test_split method we are not able to not obtain the score which is stable and it keeps on changing but we can use random_state parameter to produce same output everytime, but even then we have a problem i.e., we are not able to obtain the average score of taking all different datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1efdc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu_score(model,X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    return model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994df76",
   "metadata": {},
   "source": [
    "### KFold vs StratifiedKFold Testing:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b860695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train iteration 1: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "y_test iteration 1: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_train iteration 2: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "y_test iteration 2: \n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "y_train iteration 3: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "y_test iteration 3: \n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "mean accuarcy score of Logistic Regression model : 0.0\n",
      "mean accuarcy score of SVM classifier model : 0.0\n",
      "mean accuarcy score of RandomForest Classifier model : 0.0\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "re_skf = RepeatedStratifiedKFold(n_splits=3,n_repeats = 3)\n",
    "#models creation\n",
    "L_Reg = LogisticRegression(n_jobs=3)\n",
    "svmc = SVC()\n",
    "rfc = RandomForestClassifier(n_jobs=3)\n",
    "lst_L_Reg = list()\n",
    "lst_svmc = list()\n",
    "lst_rfc = list()\n",
    "i=0\n",
    "for train_index,test_index in kf.split(iris_dataset.data):\n",
    "    X_train,X_test,y_train,y_test = iris_dataset.data[train_index],iris_dataset.data[test_index],\\\n",
    "    iris_dataset.target[train_index],iris_dataset.target[test_index]\n",
    "    i=i+1\n",
    "    print(f'y_train iteration {i}: \\n {y_train}')\n",
    "    print(f'y_test iteration {i}: \\n {y_test}')\n",
    "    lst_L_Reg.append(accu_score(L_Reg,X_train,X_test,y_train,y_test))\n",
    "    lst_svmc.append(accu_score(svmc,X_train,X_test,y_train,y_test))\n",
    "    lst_rfc.append(accu_score(rfc,X_train,X_test,y_train,y_test))\n",
    "print(f'mean accuarcy score of Logistic Regression model : {np.mean(lst_L_Reg)}')\n",
    "print(f'mean accuarcy score of SVM classifier model : {np.mean(lst_svmc)}')\n",
    "print(f'mean accuarcy score of RandomForest Classifier model : {np.mean(lst_rfc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4436454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train iteration 1: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "dtype: int64\n",
      "y_test iteration 1: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "dtype: int64\n",
      "y_train iteration 2: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "dtype: int64\n",
      "y_test iteration 2: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "dtype: int64\n",
      "y_train iteration 3: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "dtype: int64\n",
      "y_test iteration 3: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "dtype: int64\n",
      "mean accuarcy score of Logistic Regression model : 0.9733333333333333\n",
      "mean accuarcy score of SVM classifier model : 0.96\n",
      "mean accuarcy score of RandomForest Classifier model : 0.96\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "lst_L_Reg = list()\n",
    "lst_svmc = list()\n",
    "lst_rfc = list()\n",
    "for train_index,test_index in skf.split(iris_dataset.data,iris_dataset.target):\n",
    "    X_train,X_test,y_train,y_test = iris_dataset.data[train_index],iris_dataset.data[test_index],\\\n",
    "    iris_dataset.target[train_index],iris_dataset.target[test_index]\n",
    "    i=i+1\n",
    "    print(f'y_train iteration {i}: \\n {y_train} \\n counts of each label: \\n {pd.Series(y_train).value_counts()}')\n",
    "    print(f'y_test iteration {i}: \\n {y_test} \\n counts of each label: \\n {pd.Series(y_test).value_counts()}')\n",
    "    \n",
    "    lst_L_Reg.append(accu_score(L_Reg,X_train,X_test,y_train,y_test))\n",
    "    lst_svmc.append(accu_score(svmc,X_train,X_test,y_train,y_test))\n",
    "    lst_rfc.append(accu_score(rfc,X_train,X_test,y_train,y_test))\n",
    "print(f'mean accuarcy score of Logistic Regression model : {np.mean(lst_L_Reg)}')\n",
    "print(f'mean accuarcy score of SVM classifier model : {np.mean(lst_svmc)}')\n",
    "print(f'mean accuarcy score of RandomForest Classifier model : {np.mean(lst_rfc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648e090",
   "metadata": {},
   "source": [
    "#### StratifiedKFold vs KFold\n",
    "\n",
    "Using RepeatedStratifiedKFold means that each time running the procedure would result in a different split of the dataset into stratified k-folds, and hence, the performance results would be different.\n",
    "\n",
    "RepeatedStratifiedKFold has the benefit of improving the estimated model's performance at the cost of fitting and evaluating many more models. If, for example, 5 repeats (i.e., n_repeats=5) of 10-fold cross-validation were used for estimating the model's performance, it means that 50 different models would need to be fitted (trained) and evaluated—which might be computationally expensive, depending on the dataset's size, type of machine learning algorithm, device specifications, etc. However, RepeatedStratifiedKFold process could be executed on different cores or different machines, which could dramatically speed up the process. For instance, setting n_jobs=-1 would use all the cores available on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f0fe143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train iteration 1: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "dtype: int64\n",
      "y_test iteration 1: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " counts of each label: \n",
      "0    17\n",
      "1    17\n",
      "2    16\n",
      "dtype: int64\n",
      "y_train iteration 2: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "dtype: int64\n",
      "y_test iteration 2: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " counts of each label: \n",
      "0    17\n",
      "2    17\n",
      "1    16\n",
      "dtype: int64\n",
      "y_train iteration 3: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "dtype: int64\n",
      "y_test iteration 3: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " counts of each label: \n",
      "1    17\n",
      "2    17\n",
      "0    16\n",
      "dtype: int64\n",
      "y_train iteration 4: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "dtype: int64\n",
      "y_test iteration 4: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " counts of each label: \n",
      "0    17\n",
      "1    17\n",
      "2    16\n",
      "dtype: int64\n",
      "y_train iteration 5: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "dtype: int64\n",
      "y_test iteration 5: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " counts of each label: \n",
      "0    17\n",
      "2    17\n",
      "1    16\n",
      "dtype: int64\n",
      "y_train iteration 6: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "dtype: int64\n",
      "y_test iteration 6: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " counts of each label: \n",
      "1    17\n",
      "2    17\n",
      "0    16\n",
      "dtype: int64\n",
      "y_train iteration 7: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "dtype: int64\n",
      "y_test iteration 7: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " counts of each label: \n",
      "0    17\n",
      "1    17\n",
      "2    16\n",
      "dtype: int64\n",
      "y_train iteration 8: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "dtype: int64\n",
      "y_test iteration 8: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " counts of each label: \n",
      "0    17\n",
      "2    17\n",
      "1    16\n",
      "dtype: int64\n",
      "y_train iteration 9: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      " counts of each label: \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "dtype: int64\n",
      "y_test iteration 9: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      " counts of each label: \n",
      "1    17\n",
      "2    17\n",
      "0    16\n",
      "dtype: int64\n",
      "mean accuarcy score of Logistic Regression model : 0.9600000000000001\n",
      "mean accuarcy score of SVM classifier model : 0.9555555555555555\n",
      "mean accuarcy score of RandomForest Classifier model : 0.951111111111111\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "lst_L_Reg = list()\n",
    "lst_svmc = list()\n",
    "lst_rfc = list()\n",
    "for train_index,test_index in re_skf.split(iris_dataset.data,iris_dataset.target):\n",
    "    X_train,X_test,y_train,y_test = iris_dataset.data[train_index],iris_dataset.data[test_index],\\\n",
    "    iris_dataset.target[train_index],iris_dataset.target[test_index]\n",
    "    i=i+1\n",
    "    print(f'y_train iteration {i}: \\n {y_train} \\n counts of each label: \\n',pd.Series(y_train).value_counts())\n",
    "    print(f'y_test iteration {i}: \\n  {y_test}\\n counts of each label: \\n{pd.Series(y_test).value_counts()}')\n",
    "    \n",
    "    lst_L_Reg.append(accu_score(L_Reg,X_train,X_test,y_train,y_test))\n",
    "    lst_svmc.append(accu_score(svmc,X_train,X_test,y_train,y_test))\n",
    "    lst_rfc.append(accu_score(rfc,X_train,X_test,y_train,y_test))\n",
    "print(f'mean accuarcy score of Logistic Regression model : {np.mean(lst_L_Reg)}')\n",
    "print(f'mean accuarcy score of SVM classifier model : {np.mean(lst_svmc)}')\n",
    "print(f'mean accuarcy score of RandomForest Classifier model : {np.mean(lst_rfc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa2f47",
   "metadata": {},
   "source": [
    "As we can see that here StratifiedKFold considers the y-labels and does the splitting of the dataset based on them ensuring that there is equal distribution of them in each of the splitting, i.e., it tries to maintain almost same no. of labels from each class in the dataset. Where as in KFold we can see that there is imbalance of the labels in the dataset as they have only labels of 2 classes in the train and remaining 1 label in the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf7b70",
   "metadata": {},
   "source": [
    "### class sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, random_state=None)\n",
    "\n",
    "K-Folds cross-validator\n",
    "\n",
    "Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default).\n",
    "\n",
    "Each fold is then used once as a validation while the k - 1 remaining folds form the training set.\n",
    "\n",
    "*Parameters*:\n",
    "\n",
    "*n_splits* : int, default=5\n",
    "\n",
    "Number of folds. Must be at least 2.\n",
    "\n",
    "Changed in version 0.22: n_splits default value changed from 3 to 5.\n",
    "\n",
    "*shuffle* : bool, default=False\n",
    "\n",
    "Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled.\n",
    "\n",
    "*random_state* :int, RandomState instance or None, default=None\n",
    "\n",
    "When shuffle is True, random_state affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect. Pass an int for reproducible output across multiple function calls. See Glossary.\n",
    "\n",
    "\n",
    "split method:\n",
    "\n",
    "*split*:(X, y=None, groups=None)\n",
    "Generate indices to split data into training and test set.\n",
    "\n",
    "Parameters:\n",
    "'X':array-like of shape (n_samples, n_features)\n",
    "Training data, where n_samples is the number of samples and n_features is the number of features.\n",
    "\n",
    "'y':array-like of shape (n_samples,), default=None\n",
    "The target variable for supervised learning problems.\n",
    "\n",
    "'groups':array-like of shape (n_samples,), default=None\n",
    "Group labels for the samples used while splitting the dataset into train/test set.\n",
    "\n",
    "Yields:\n",
    "'train':ndarray\n",
    "The training set indices for that split.\n",
    "\n",
    "'test':ndarray\n",
    "The testing set indices for that split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e9dc6",
   "metadata": {},
   "source": [
    "### Stratified K-Folds cross-validator\n",
    "\n",
    "Provides train/test indices to split data in train/test sets.\n",
    "\n",
    "This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "Parameters:\t\n",
    "\n",
    "*n_splits* : int, default=3\n",
    "\n",
    "Number of folds. Must be at least 2.\n",
    "\n",
    "*shuffle* : boolean, optional\n",
    "\n",
    "Whether to shuffle each stratification of the data before splitting into batches.\n",
    "\n",
    "*random_state* : int, RandomState instance or None, optional, default=None\n",
    "\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random. Used when shuffle == True.\n",
    "\n",
    "*split method*\n",
    "\n",
    "split(X, y, groups=None)\n",
    "Generate indices to split data into training and test set.\n",
    "\n",
    "Parameters:\t\n",
    "*X* : array-like, shape (n_samples, n_features)\n",
    "\n",
    "Training data, where n_samples is the number of samples and n_features is the number of features.\n",
    "\n",
    "Note that providing y is sufficient to generate the splits and hence np.zeros(n_samples) may be used as a placeholder for X instead of actual training data.\n",
    "\n",
    "*y* : array-like, shape (n_samples,)\n",
    "\n",
    "The target variable for supervised learning problems. Stratification is done based on the y labels.\n",
    "\n",
    "*groups* : object\n",
    "\n",
    "Always ignored, exists for compatibility.\n",
    "\n",
    "Returns:\t\n",
    "\n",
    "*train* : ndarray\n",
    "\n",
    "The training set indices for that split.\n",
    "\n",
    "*test* : ndarray\n",
    "\n",
    "The testing set indices for that split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b0142",
   "metadata": {},
   "source": [
    "*if cv has int value and estimator is a classifier then it uses stratified k fold otherwise it uses k fold stratergy*\n",
    "\n",
    "*cv*:int, cross-validation generator or an iterable, default=None\n",
    "\n",
    "Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
    "\n",
    "None, to use the default 5-fold cross validation,\n",
    "\n",
    "int, to specify the number of folds in a (Stratified)KFold,\n",
    "\n",
    "CV splitter,\n",
    "\n",
    "An iterable that generates (train, test) splits as arrays of indices.\n",
    "\n",
    "For int/None inputs, if the estimator is a classifier and y is either binary or multiclass, \n",
    "StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with \n",
    "shuffle=False so the splits will be the same across calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a33cf790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuarcy scores: [0.96666667 1.         0.93333333 0.96666667 1.        ] mean score: 0.9733333333333334\n",
      "svm classifier accuracy scores: [0.96666667 0.96666667 0.96666667 0.93333333 1.        ] mean score: 0.9666666666666666\n",
      "rf classifier accuarcy scores: [0.96666667 0.96666667 0.93333333 0.9        1.        ] mean score: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression accuarcy scores: {cross_val_score(L_Reg,iris_dataset.data,iris_dataset.target)} mean score: {np.mean(cross_val_score(L_Reg,iris_dataset.data,iris_dataset.target))}')\n",
    "print(f'svm classifier accuracy scores: {cross_val_score(svmc,iris_dataset.data,iris_dataset.target)} mean score: {np.mean(cross_val_score(svmc,iris_dataset.data,iris_dataset.target))}')\n",
    "print(f'rf classifier accuarcy scores: {cross_val_score(rfc,iris_dataset.data,iris_dataset.target)} mean score: {np.mean(cross_val_score(rfc,iris_dataset.data,iris_dataset.target))}')\n",
    "\n",
    "#as it has default 5-fold cross validation which is stratifiedkfold it has slight improvement of \n",
    "#accuracy for L_reg and svm models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea56b8",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "Logistic Regression performed the better than svmc and rfc with an accuracy 97.34 percentage in classifying flowers of load_iris dataset and then svm has achieved accuracy of 96.67 percentage and random forest classifier has achieved an accuarcy of 96.67 percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4233f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
